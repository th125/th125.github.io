---
layout: post
title: Decision Tree
date: 2019-02-10 22:36:00
---

분류 회귀작업 다중출력 작업이 가능함
결정 트리는 랜덤 포레스트의 기본 구성 요소

결정 트리의 훈련, 시각화, 예측 방법
트리에 규제를 가하는 방법
회귀문제에 적용하는 방법

!붓꽃 데이터

!결정 트리 학습

결정 트리의 장점
    데이터 전처리가 거의 필요하지 않음

노드의 gini 속성은 불순도를 측정함
    한 노드의 모든 샘플이 같은 클래스에 속해 있다면 이 노드를 순수(gini=0)하다고 함

sklean은 이진 트리만 만드는 CART 알고리즘을 사용하므로 리프 노드외의 모든 노드는 두개의 자식 노드를 가짐
CART : Classification And Regression Tree
    훈련 세트를 하나의 특성 k의 임계값 tk를 사용해 두개의 서브 셋으로 나눔
    k, tk를 고르는 방법은 가장 순수한 서브셋으로 나눌 수 있는 짝을 찾는 것

ID3 알고리즘은 둘 이상의 자식 노드를 가진 결정트리를 만들 수 있음

결정트리는 화이트박스 모델이라고 함
    매우 직관적이고 결정 방식을 이해하기 쉽다.

랜덤포레스트, 신경망은 블랙박스 모델이라고 함
    성능이 뛰어나고 예측을 만드는 연산과정을 쉽게 확인할 수 있음
    왜 그런 예측을 만드는지는 쉽게 설명하기 어려움

예측하기
    트리의 각 노드는 조건을 가지고 있음
    조건에 따라 분기가 발생하여 샘플을 분류할 수 있음 (리프노드)

클래스 확률 추정
    결정 트리는 한 샘플이 특정 클래스 k에 속할 확률을 추정할 수 있음
